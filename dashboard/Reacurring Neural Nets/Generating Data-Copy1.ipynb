{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesizing Data \n",
    "## By: Lela Bones\n",
    "-----------------------------------\n",
    "### Problem\n",
    "    Nestor is an application that allows users to datify their maintenance logs. Datify is the process of taking unorginized data and putting it into a quantifiable and statistically relevant format. The problem is that because of copywright and data ownership technicalities, it is hard for us to have a large amount of \"good\" data to demo our app on. \n",
    "\n",
    "### Solution\n",
    "    I plan on using Reccurent Neural Nets (RNNs) to generate realistic data from the data that we already have from companies. The reason for this is because we can use the \"synthetic\" data to demo our app on, and we aren't breaking any laws. I plan on using a Python library, Pytorch to implement my RNN and train it on the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Pytorch???\n",
    "Pytorch is a framework that builds from the Torch framework that Facebook actively uses. Pytorch is extremely fast it is very native and customizable. Pytorch is also a dynamic deep learning tool, which means that you can change and execute notes as you're learning. This makes RNNs way easier to train because you don't need to set a maximum length and then pad smaller sequences. Debugging is really easy because it is defined at runtime. It works well with Flask, which is the tool that I am using to create my visual dashboard. Pytorch also has declarative data parallelism which allows you to use multiple GPUs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why RNNs???\n",
    "    * Vanilla Neural Networks relearn each iteration\n",
    "    * Long Short Term Memory Neural Nets are good for long-term data\n",
    "    * Maybe GRU Neural Nets, they get rid of the disappearing gradient problem\n",
    "    * RNNs implement loops so the learning is compositional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pandas\n",
    "#conda install pytorch torchvision -c pytorch\n",
    "#conda install numpy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data file, column you want extracted, and output file\n",
    "csv_file = 'mine_raw.csv'\n",
    "txt_file = 'train.txt'\n",
    "text_col = 'OriginalShorttext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function converts the column of text from your csv file \n",
    "#to a text file that has each row on a seperate line\n",
    "#code modified from https://stackoverflow.com/questions/47339698/how-to-convert-csv-file-to-text-file-using-python\n",
    "def createTextFile(inputFile, text, outputFile):\n",
    "    df = pd.read_csv(inputFile)\n",
    "    data = df[text].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "    text_list = []\n",
    "    for line in data:\n",
    "        text_list.append(\" \".join(line))\n",
    "    \n",
    "    #switch to a+ if you want to append to existing file\n",
    "    with open(outputFile, \"w+\") as output_file:\n",
    "        for line in data:\n",
    "            output_file.write(\"  \" + line + \"\\n\")\n",
    "        #verification that it's finished\n",
    "        print('File Successfully written.')\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Successfully written.\n"
     ]
    }
   ],
   "source": [
    "createTextFile(csv_file, text_col, txt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Attempt\n",
    "The majority of this code was modified from https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 165817\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file = unidecode.unidecode(open(txt_file).read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "#splitting up the code into random chunks each the size of 200\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 10,  11,  12,  39,  40,  41])\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c].unsqueeze(0))\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msid/ltb3/anaconda3/envs/nestorDev/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0m 37s (100 5%) 1.8912]\n",
      "Wh6KR6h6HLB\n",
      "  rick trotstho\n",
      "  don leakin ol tup stir takt alg bo r/h oling\n",
      "  wir ang sil wrepam moan n \n",
      "\n",
      "[1m 19s (200 10%) 2.0013]\n",
      "Whss on woth shyd 24104\n",
      "  replace hose line hose out\n",
      "  replh r/h prepace line l/h  hyd liling l/h buck \n",
      "\n",
      "[1m 56s (300 15%) 1.4132]\n",
      "Whand motoat switexs\n",
      "  harmids leak ~ rh engine pump\n",
      "  replace ~ talank leaking leake)\n",
      "  replace chang \n",
      "\n",
      "[2m 35s (400 20%) 1.1199]\n",
      "Whk mairs\n",
      "  repair repair bucket start toom hfidys\n",
      "  al bext oils not working\n",
      "  reasre looth over toor \n",
      "\n",
      "[3m 18s (500 25%) 1.1332]\n",
      "Wh hand ring ousing aproken eal shd24\n",
      "  replace boom alant\n",
      "  replace arem fileget filtern pressins\n",
      "  r \n",
      "\n",
      "[4m 1s (600 30%) 1.0488]\n",
      "Wh slew bot on bolts oulter start under\n",
      "  cramp broken grease shd 4 replace coor 4\n",
      "  replace for ganer \n",
      "\n",
      "[4m 44s (700 35%) 1.4145]\n",
      "Wh bucket top\n",
      "  rh alarr shd24.\n",
      "  repair and shd0024\n",
      "  repair bucket tooth\n",
      "  repair aday grease\n",
      "  repa \n",
      "\n",
      "[5m 19s (800 40%) 1.2525]\n",
      "Wh fire rimessor wofff pump senters\n",
      "  replace block in creplaces splate ring\n",
      "  water hissigar\n",
      "  mater  \n",
      "\n",
      "[5m 59s (900 45%) 1.4187]\n",
      "Wh\n",
      "  grease calator shd24\n",
      "  rack filter hose\n",
      "  changeout riveal oil steelt\n",
      "  rh bucket tooth\n",
      "  repair  \n",
      "\n",
      "[6m 40s (1000 50%) 0.8700]\n",
      "Wh slew moruit thes on motork\n",
      "  broken blowigle tooth\n",
      "  damage creas leaking\n",
      "  lh engine warricket\n",
      "  r \n",
      "\n",
      "[7m 25s (1100 55%) 1.2636]\n",
      "Wh air changeout ~ stick top spauls\n",
      "  rf uist cooling ver valve\n",
      "  pump hydraulic oil comming leak (hos \n",
      "\n",
      "[8m 5s (1200 60%) 1.3749]\n",
      "Wh-wayping on bude filters\n",
      "  repair gaining down oil leak\n",
      "  side oil leak\n",
      "  repair slew ind fault d/o  \n",
      "\n",
      "[8m 42s (1300 65%) 1.0517]\n",
      "Wh slew hose\n",
      "  oil leak and clammines.oing\n",
      "  replace grease line on bolt r/h slew motor hose blown hos \n",
      "\n",
      "[9m 20s (1400 70%) 0.7619]\n",
      "Whly #01 dampstick\n",
      "  replace grease lines on boom block\n",
      "  repair car fitter changeout.\n",
      "  cleane light  \n",
      "\n",
      "[9m 57s (1500 75%) 1.4143]\n",
      "Wh fault piresinovjo\n",
      "  hyd oin shd24  rh maunt shd24\n",
      "  replace lh shd24\n",
      "  slew tramps damage depear sh \n",
      "\n",
      "[10m 44s (1600 80%) 0.9683]\n",
      "Wh bucket leak\n",
      "  replace blown loble lhs slew boom box on brake\n",
      "  grease leak l/h engine wons engine t \n",
      "\n",
      "[11m 24s (1700 85%) 1.1574]\n",
      "Wh indarter hoses after cleaning\n",
      "  repair haunting on complecting on.\n",
      "  replace lh leak idler hose doo \n",
      "\n",
      "[12m 6s (1800 90%) 1.1625]\n",
      "Wh box conditioner gald dank\n",
      "  oil blocking a/c compretooth.\n",
      "  replace repair engine alarm fan @16 bot \n",
      "\n",
      "[12m 51s (1900 95%) 1.5989]\n",
      "Wh a/c\n",
      "  replace fit tip\n",
      "  rh travel hot histor\n",
      "  lines on slew motor repair pin\n",
      "  replace lidsing oil \n",
      "\n",
      "[13m 34s (2000 100%) 1.6275]\n",
      "Wh neection in strack\n",
      "  replace alarm\n",
      "  right screec fac\n",
      "  lube not woper motor\n",
      "  replace switch cylin \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f999a764a20>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Attempt\n",
    "Most of this code is from https://github.com/mcleonard/pytorch-charRNN/blob/master/TorchRNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "with open (txt_file, 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert char to int\n",
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns mini-batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "    '''\n",
    "    \n",
    "    batch_size = n_seqs * n_steps\n",
    "    n_batches = len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size]\n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+n_steps]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y\n",
    "\n",
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, tokens, n_steps=100, n_hidden=256, n_layers=2,\n",
    "                               drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, x, hc):\n",
    "        ''' Forward pass through the network '''\n",
    "        \n",
    "        x, (h, c) = self.lstm(x, hc)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Stack up LSTM outputs\n",
    "        x = x.view(x.size()[0]*x.size()[1], self.n_hidden)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x, (h, c)\n",
    "    \n",
    "    def predict(self, char, h=None, cuda=False, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "        \n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        if cuda:\n",
    "            self.cuda()\n",
    "        else:\n",
    "            self.cpu()\n",
    "        \n",
    "        if h is None:\n",
    "            h = self.init_hidden(1)\n",
    "        \n",
    "        x = np.array([[self.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(self.chars))\n",
    "        inputs = Variable(torch.from_numpy(x), volatile=True)\n",
    "        if cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        h = tuple([Variable(each.data, volatile=True) for each in h])\n",
    "        out, h = self.forward(inputs, h)\n",
    "\n",
    "        p = F.softmax(out).data\n",
    "        if cuda:\n",
    "            p = p.cpu()\n",
    "        \n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(self.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "            \n",
    "        return self.int2char[char], h\n",
    "    \n",
    "    def init_weights(self):\n",
    "        ''' Initialize weights for fully connected layer '''\n",
    "        initrange = 0.1\n",
    "        \n",
    "        # Set bias tensor to all zeros\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        # FC weights as random uniform\n",
    "        self.fc.weight.data.uniform_(-1, 1)\n",
    "        \n",
    "    def init_hidden(self, n_seqs):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        return (Variable(weight.new(self.n_layers, n_seqs, self.n_hidden).zero_()),\n",
    "                Variable(weight.new(self.n_layers, n_seqs, self.n_hidden).zero_()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data, epochs=10, n_seqs=10, n_steps=50, lr=0.001, clip=5, val_frac=0.1, cuda=False, print_every=10):\n",
    "    ''' Traing a network \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        net: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        n_seqs: Number of mini-sequences per mini-batch, aka batch size\n",
    "        n_steps: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        cuda: Train with CUDA on a GPU\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    net.train()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    val_idx = int(len(data)*(1-val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "    \n",
    "    if cuda:\n",
    "        net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e in range(epochs):\n",
    "        h = net.init_hidden(n_seqs)\n",
    "        for x, y in get_batches(data, n_seqs, n_steps):\n",
    "            counter += 1\n",
    "            \n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            inputs, targets = Variable(x), Variable(y)\n",
    "            if cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([Variable(each.data) for each in h])\n",
    "\n",
    "            net.zero_grad()\n",
    "            \n",
    "            output, h = net.forward(inputs, h)\n",
    "            loss = criterion(output, targets.view(n_seqs*n_steps))\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "\n",
    "            opt.step()\n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "                \n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(n_seqs)\n",
    "                val_losses = []\n",
    "                for x, y in get_batches(val_data, n_seqs, n_steps):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([Variable(each.data, volatile=True) for each in val_h])\n",
    "                    \n",
    "                    inputs, targets = Variable(x, volatile=True), Variable(y, volatile=True)\n",
    "                    if cuda:\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output, val_h = net.forward(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets.view(n_seqs*n_steps))\n",
    "                \n",
    "                    val_losses.append(val_loss.data[0])\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.data[0]),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msid/ltb3/anaconda3/envs/nestorDev/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "/home/msid/ltb3/anaconda3/envs/nestorDev/lib/python3.6/site-packages/ipykernel_launcher.py:74: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/msid/ltb3/anaconda3/envs/nestorDev/lib/python3.6/site-packages/ipykernel_launcher.py:76: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/msid/ltb3/anaconda3/envs/nestorDev/lib/python3.6/site-packages/ipykernel_launcher.py:83: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/msid/ltb3/anaconda3/envs/nestorDev/lib/python3.6/site-packages/ipykernel_launcher.py:87: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25... Step: 10... Loss: 3.4990... Val Loss: 3.4705\n",
      "Epoch: 1/25... Step: 20... Loss: 3.0711... Val Loss: 3.3570\n",
      "Epoch: 1/25... Step: 30... Loss: 3.1354... Val Loss: 3.1969\n",
      "Epoch: 1/25... Step: 40... Loss: 2.0497... Val Loss: 3.0917\n",
      "Epoch: 1/25... Step: 50... Loss: 2.1963... Val Loss: 3.0905\n",
      "Epoch: 1/25... Step: 60... Loss: 2.5658... Val Loss: 2.9211\n",
      "Epoch: 1/25... Step: 70... Loss: 2.8160... Val Loss: 3.1486\n",
      "Epoch: 1/25... Step: 80... Loss: 1.6296... Val Loss: 3.0910\n",
      "Epoch: 1/25... Step: 90... Loss: 2.0576... Val Loss: 2.9641\n",
      "Epoch: 1/25... Step: 100... Loss: 1.5698... Val Loss: 2.9413\n",
      "Epoch: 1/25... Step: 110... Loss: 1.1244... Val Loss: 2.9723\n",
      "Epoch: 1/25... Step: 120... Loss: 2.5040... Val Loss: 3.1286\n",
      "Epoch: 1/25... Step: 130... Loss: 1.1422... Val Loss: 2.9360\n",
      "Epoch: 1/25... Step: 140... Loss: 1.1540... Val Loss: 2.8554\n",
      "Epoch: 1/25... Step: 150... Loss: 2.2376... Val Loss: 3.1941\n",
      "Epoch: 1/25... Step: 160... Loss: 1.6501... Val Loss: 2.7525\n",
      "Epoch: 1/25... Step: 170... Loss: 0.6243... Val Loss: 3.0004\n",
      "Epoch: 1/25... Step: 180... Loss: 1.5197... Val Loss: 2.9830\n",
      "Epoch: 1/25... Step: 190... Loss: 0.8961... Val Loss: 2.9698\n",
      "Epoch: 1/25... Step: 200... Loss: 0.4207... Val Loss: 3.0590\n",
      "Epoch: 1/25... Step: 210... Loss: 0.9272... Val Loss: 2.9327\n",
      "Epoch: 1/25... Step: 220... Loss: 1.9397... Val Loss: 2.9870\n",
      "Epoch: 1/25... Step: 230... Loss: 1.3309... Val Loss: 2.8023\n",
      "Epoch: 1/25... Step: 240... Loss: 0.9644... Val Loss: 2.7255\n",
      "Epoch: 1/25... Step: 250... Loss: 2.5801... Val Loss: 2.8239\n",
      "Epoch: 1/25... Step: 260... Loss: 1.7421... Val Loss: 2.6155\n",
      "Epoch: 1/25... Step: 270... Loss: 1.1877... Val Loss: 2.7181\n",
      "Epoch: 1/25... Step: 280... Loss: 2.0213... Val Loss: 2.9790\n",
      "Epoch: 1/25... Step: 290... Loss: 1.9330... Val Loss: 2.6726\n",
      "Epoch: 1/25... Step: 300... Loss: 0.4991... Val Loss: 3.4186\n",
      "Epoch: 1/25... Step: 310... Loss: 0.8608... Val Loss: 2.7820\n",
      "Epoch: 1/25... Step: 320... Loss: 0.6824... Val Loss: 2.9733\n",
      "Epoch: 1/25... Step: 330... Loss: 1.7813... Val Loss: 2.8062\n",
      "Epoch: 1/25... Step: 340... Loss: 1.8339... Val Loss: 2.6413\n",
      "Epoch: 1/25... Step: 350... Loss: 0.9101... Val Loss: 2.9388\n",
      "Epoch: 1/25... Step: 360... Loss: 1.0726... Val Loss: 2.8347\n",
      "Epoch: 1/25... Step: 370... Loss: 2.1230... Val Loss: 2.6633\n",
      "Epoch: 1/25... Step: 380... Loss: 1.3103... Val Loss: 2.6916\n",
      "Epoch: 1/25... Step: 390... Loss: 1.5568... Val Loss: 2.7151\n",
      "Epoch: 1/25... Step: 400... Loss: 1.4253... Val Loss: 2.6103\n",
      "Epoch: 1/25... Step: 410... Loss: 0.8671... Val Loss: 2.8594\n",
      "Epoch: 1/25... Step: 420... Loss: 1.8619... Val Loss: 2.6559\n",
      "Epoch: 1/25... Step: 430... Loss: 0.4724... Val Loss: 2.6318\n",
      "Epoch: 1/25... Step: 440... Loss: 1.7745... Val Loss: 2.6777\n",
      "Epoch: 1/25... Step: 450... Loss: 2.2051... Val Loss: 2.5791\n",
      "Epoch: 1/25... Step: 460... Loss: 1.9133... Val Loss: 2.5774\n",
      "Epoch: 1/25... Step: 470... Loss: 1.8770... Val Loss: 2.4467\n",
      "Epoch: 1/25... Step: 480... Loss: 2.9532... Val Loss: 2.5202\n",
      "Epoch: 1/25... Step: 490... Loss: 1.4106... Val Loss: 2.5126\n",
      "Epoch: 1/25... Step: 500... Loss: 1.1651... Val Loss: 2.5908\n",
      "Epoch: 1/25... Step: 510... Loss: 1.8431... Val Loss: 2.4073\n",
      "Epoch: 1/25... Step: 520... Loss: 2.5335... Val Loss: 2.4416\n",
      "Epoch: 1/25... Step: 530... Loss: 1.6018... Val Loss: 2.3865\n",
      "Epoch: 1/25... Step: 540... Loss: 1.4034... Val Loss: 2.4385\n",
      "Epoch: 1/25... Step: 550... Loss: 1.3899... Val Loss: 2.3878\n",
      "Epoch: 1/25... Step: 560... Loss: 1.3647... Val Loss: 2.3445\n",
      "Epoch: 1/25... Step: 570... Loss: 1.8263... Val Loss: 2.4214\n",
      "Epoch: 1/25... Step: 580... Loss: 2.0059... Val Loss: 2.3470\n",
      "Epoch: 1/25... Step: 590... Loss: 1.9349... Val Loss: 2.3913\n",
      "Epoch: 1/25... Step: 600... Loss: 1.7537... Val Loss: 2.2972\n",
      "Epoch: 1/25... Step: 610... Loss: 2.0932... Val Loss: 2.3249\n",
      "Epoch: 1/25... Step: 620... Loss: 1.2069... Val Loss: 2.2987\n",
      "Epoch: 1/25... Step: 630... Loss: 1.0486... Val Loss: 2.2380\n",
      "Epoch: 1/25... Step: 640... Loss: 1.6344... Val Loss: 2.2661\n",
      "Epoch: 1/25... Step: 650... Loss: 1.0379... Val Loss: 2.2528\n",
      "Epoch: 1/25... Step: 660... Loss: 1.7106... Val Loss: 2.4365\n",
      "Epoch: 1/25... Step: 670... Loss: 1.2324... Val Loss: 2.5056\n",
      "Epoch: 1/25... Step: 680... Loss: 0.9496... Val Loss: 2.5307\n",
      "Epoch: 1/25... Step: 690... Loss: 1.4266... Val Loss: 2.6759\n",
      "Epoch: 1/25... Step: 700... Loss: 1.3899... Val Loss: 2.4040\n",
      "Epoch: 1/25... Step: 710... Loss: 0.4520... Val Loss: 2.5619\n",
      "Epoch: 1/25... Step: 720... Loss: 1.0337... Val Loss: 2.4871\n",
      "Epoch: 1/25... Step: 730... Loss: 0.5146... Val Loss: 2.5152\n",
      "Epoch: 1/25... Step: 740... Loss: 0.7188... Val Loss: 21.9122\n",
      "Epoch: 1/25... Step: 750... Loss: 1.4298... Val Loss: 2.5053\n",
      "Epoch: 1/25... Step: 760... Loss: 1.1399... Val Loss: 2.6854\n",
      "Epoch: 1/25... Step: 770... Loss: 1.4127... Val Loss: 2.4423\n",
      "Epoch: 1/25... Step: 780... Loss: 2.8374... Val Loss: 2.3894\n",
      "Epoch: 1/25... Step: 790... Loss: 1.6260... Val Loss: 2.3438\n",
      "Epoch: 1/25... Step: 800... Loss: 1.1954... Val Loss: 2.3675\n",
      "Epoch: 1/25... Step: 810... Loss: 1.6954... Val Loss: 2.3091\n",
      "Epoch: 1/25... Step: 820... Loss: 2.1598... Val Loss: 2.2959\n",
      "Epoch: 1/25... Step: 830... Loss: 0.9916... Val Loss: 2.3791\n",
      "Epoch: 1/25... Step: 840... Loss: 0.6712... Val Loss: 2.3080\n",
      "Epoch: 1/25... Step: 850... Loss: 1.1485... Val Loss: 2.3428\n",
      "Epoch: 1/25... Step: 860... Loss: 1.1683... Val Loss: 2.3520\n",
      "Epoch: 1/25... Step: 870... Loss: 1.5720... Val Loss: 2.1856\n",
      "Epoch: 1/25... Step: 880... Loss: 1.5085... Val Loss: 2.1710\n",
      "Epoch: 1/25... Step: 890... Loss: 2.9034... Val Loss: 2.2385\n",
      "Epoch: 1/25... Step: 900... Loss: 1.9594... Val Loss: 2.1931\n",
      "Epoch: 1/25... Step: 910... Loss: 1.5556... Val Loss: 2.3077\n",
      "Epoch: 1/25... Step: 920... Loss: 1.3020... Val Loss: 2.3525\n",
      "Epoch: 1/25... Step: 930... Loss: 2.1195... Val Loss: 2.2432\n",
      "Epoch: 1/25... Step: 940... Loss: 1.2782... Val Loss: 2.2452\n",
      "Epoch: 1/25... Step: 950... Loss: 1.9619... Val Loss: 2.5994\n",
      "Epoch: 1/25... Step: 960... Loss: 0.6998... Val Loss: 10.3485\n",
      "Epoch: 1/25... Step: 970... Loss: 1.6895... Val Loss: 40.1386\n",
      "Epoch: 1/25... Step: 980... Loss: 1.9926... Val Loss: 2.2099\n",
      "Epoch: 1/25... Step: 990... Loss: 1.4473... Val Loss: 2.2236\n",
      "Epoch: 1/25... Step: 1000... Loss: 1.4602... Val Loss: 2.2458\n",
      "Epoch: 1/25... Step: 1010... Loss: 1.8439... Val Loss: 2.2850\n",
      "Epoch: 1/25... Step: 1020... Loss: 1.8670... Val Loss: 2.3165\n",
      "Epoch: 1/25... Step: 1030... Loss: 1.3525... Val Loss: 2.1871\n",
      "Epoch: 1/25... Step: 1040... Loss: 1.2757... Val Loss: 2.2273\n",
      "Epoch: 1/25... Step: 1050... Loss: 1.9412... Val Loss: 2.2788\n",
      "Epoch: 1/25... Step: 1060... Loss: 2.9987... Val Loss: 2.2418\n",
      "Epoch: 1/25... Step: 1070... Loss: 1.5239... Val Loss: 2.2542\n",
      "Epoch: 1/25... Step: 1080... Loss: 0.7404... Val Loss: 2.3285\n",
      "Epoch: 1/25... Step: 1090... Loss: 1.1191... Val Loss: 2.3583\n",
      "Epoch: 1/25... Step: 1100... Loss: 1.6238... Val Loss: 2.1984\n",
      "Epoch: 1/25... Step: 1110... Loss: 1.7127... Val Loss: 2.3017\n",
      "Epoch: 1/25... Step: 1120... Loss: 2.1705... Val Loss: 2.3231\n",
      "Epoch: 1/25... Step: 1130... Loss: 1.4237... Val Loss: 2.1152\n",
      "Epoch: 1/25... Step: 1140... Loss: 1.9478... Val Loss: 2.1391\n",
      "Epoch: 1/25... Step: 1150... Loss: 1.4357... Val Loss: 2.1729\n",
      "Epoch: 1/25... Step: 1160... Loss: 1.5678... Val Loss: 2.1493\n",
      "Epoch: 1/25... Step: 1170... Loss: 1.6248... Val Loss: 2.2045\n",
      "Epoch: 1/25... Step: 1180... Loss: 1.4668... Val Loss: 2.2003\n",
      "Epoch: 1/25... Step: 1190... Loss: 1.3958... Val Loss: 2.1438\n",
      "Epoch: 1/25... Step: 1200... Loss: 0.5542... Val Loss: 2.2266\n",
      "Epoch: 1/25... Step: 1210... Loss: 2.2691... Val Loss: 2.2494\n",
      "Epoch: 1/25... Step: 1220... Loss: 1.4721... Val Loss: 2.1420\n",
      "Epoch: 1/25... Step: 1230... Loss: 1.4927... Val Loss: 2.2897\n",
      "Epoch: 1/25... Step: 1240... Loss: 0.8861... Val Loss: 2.2043\n",
      "Epoch: 1/25... Step: 1250... Loss: 2.3391... Val Loss: 2.1186\n",
      "Epoch: 1/25... Step: 1260... Loss: 1.3929... Val Loss: 2.1459\n",
      "Epoch: 1/25... Step: 1270... Loss: 1.7159... Val Loss: 2.2521\n",
      "Epoch: 1/25... Step: 1280... Loss: 0.6076... Val Loss: 2.2517\n",
      "Epoch: 1/25... Step: 1290... Loss: 1.2333... Val Loss: 2.2111\n",
      "Epoch: 1/25... Step: 1300... Loss: 1.6892... Val Loss: 2.1962\n",
      "Epoch: 1/25... Step: 1310... Loss: 0.8336... Val Loss: 2.3041\n",
      "Epoch: 1/25... Step: 1320... Loss: 2.0509... Val Loss: 2.3096\n",
      "Epoch: 1/25... Step: 1330... Loss: 0.6021... Val Loss: 2.3406\n",
      "Epoch: 1/25... Step: 1340... Loss: 1.5676... Val Loss: 2.4152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25... Step: 1350... Loss: 1.6789... Val Loss: 2.2079\n",
      "Epoch: 1/25... Step: 1360... Loss: 2.5328... Val Loss: 2.1861\n",
      "Epoch: 1/25... Step: 1370... Loss: 1.3819... Val Loss: 2.1603\n",
      "Epoch: 1/25... Step: 1380... Loss: 1.3821... Val Loss: 2.1477\n",
      "Epoch: 1/25... Step: 1390... Loss: 1.5764... Val Loss: 2.1726\n",
      "Epoch: 1/25... Step: 1400... Loss: 1.1424... Val Loss: 2.2661\n",
      "Epoch: 1/25... Step: 1410... Loss: 1.5617... Val Loss: 2.1868\n",
      "Epoch: 1/25... Step: 1420... Loss: 1.0465... Val Loss: 2.1794\n",
      "Epoch: 1/25... Step: 1430... Loss: 0.7897... Val Loss: 2.1808\n",
      "Epoch: 1/25... Step: 1440... Loss: 0.5123... Val Loss: 2.2531\n",
      "Epoch: 1/25... Step: 1450... Loss: 1.2089... Val Loss: 2.1924\n",
      "Epoch: 1/25... Step: 1460... Loss: 1.0201... Val Loss: 2.2093\n",
      "Epoch: 1/25... Step: 1470... Loss: 1.5734... Val Loss: 2.1409\n",
      "Epoch: 1/25... Step: 1480... Loss: 2.0174... Val Loss: 2.1182\n",
      "Epoch: 1/25... Step: 1490... Loss: 0.9649... Val Loss: 2.1573\n",
      "Epoch: 1/25... Step: 1500... Loss: 1.5990... Val Loss: 2.1786\n",
      "Epoch: 1/25... Step: 1510... Loss: 1.4885... Val Loss: 2.1203\n",
      "Epoch: 1/25... Step: 1520... Loss: 1.6888... Val Loss: 2.1432\n",
      "Epoch: 1/25... Step: 1530... Loss: 1.2295... Val Loss: 2.2257\n",
      "Epoch: 1/25... Step: 1540... Loss: 1.2846... Val Loss: 2.1634\n",
      "Epoch: 1/25... Step: 1550... Loss: 1.0764... Val Loss: 2.1998\n",
      "Epoch: 1/25... Step: 1560... Loss: 0.7056... Val Loss: 2.1860\n",
      "Epoch: 1/25... Step: 1570... Loss: 0.6254... Val Loss: 2.2080\n",
      "Epoch: 1/25... Step: 1580... Loss: 1.6733... Val Loss: 2.1476\n",
      "Epoch: 1/25... Step: 1590... Loss: 1.8429... Val Loss: 2.1797\n",
      "Epoch: 1/25... Step: 1600... Loss: 0.7438... Val Loss: 2.1823\n",
      "Epoch: 1/25... Step: 1610... Loss: 2.0521... Val Loss: 2.2327\n",
      "Epoch: 1/25... Step: 1620... Loss: 0.5999... Val Loss: 2.1387\n",
      "Epoch: 1/25... Step: 1630... Loss: 1.7698... Val Loss: 2.1472\n",
      "Epoch: 1/25... Step: 1640... Loss: 1.5527... Val Loss: 2.2032\n",
      "Epoch: 1/25... Step: 1650... Loss: 1.4491... Val Loss: 2.2542\n",
      "Epoch: 1/25... Step: 1660... Loss: 0.8166... Val Loss: 2.1461\n",
      "Epoch: 1/25... Step: 1670... Loss: 1.2804... Val Loss: 2.1145\n",
      "Epoch: 1/25... Step: 1680... Loss: 0.9229... Val Loss: 2.1837\n",
      "Epoch: 1/25... Step: 1690... Loss: 1.4997... Val Loss: 2.2454\n",
      "Epoch: 1/25... Step: 1700... Loss: 2.7229... Val Loss: 2.2189\n",
      "Epoch: 1/25... Step: 1710... Loss: 2.1143... Val Loss: 2.1532\n",
      "Epoch: 1/25... Step: 1720... Loss: 1.7809... Val Loss: 2.2259\n",
      "Epoch: 1/25... Step: 1730... Loss: 1.1075... Val Loss: 2.2254\n",
      "Epoch: 1/25... Step: 1740... Loss: 0.6077... Val Loss: 2.1715\n",
      "Epoch: 1/25... Step: 1750... Loss: 1.3030... Val Loss: 2.1734\n",
      "Epoch: 1/25... Step: 1760... Loss: 1.1394... Val Loss: 2.2057\n",
      "Epoch: 1/25... Step: 1770... Loss: 1.3191... Val Loss: 2.2316\n",
      "Epoch: 1/25... Step: 1780... Loss: 1.0729... Val Loss: 2.2123\n",
      "Epoch: 1/25... Step: 1790... Loss: 1.1331... Val Loss: 2.2271\n",
      "Epoch: 1/25... Step: 1800... Loss: 1.1963... Val Loss: 2.3308\n",
      "Epoch: 1/25... Step: 1810... Loss: 1.3235... Val Loss: 2.2413\n",
      "Epoch: 1/25... Step: 1820... Loss: 1.9003... Val Loss: 2.2669\n",
      "Epoch: 1/25... Step: 1830... Loss: 1.8725... Val Loss: 2.2294\n",
      "Epoch: 1/25... Step: 1840... Loss: 1.5360... Val Loss: 2.1304\n",
      "Epoch: 1/25... Step: 1850... Loss: 1.7692... Val Loss: 2.0977\n",
      "Epoch: 1/25... Step: 1860... Loss: 1.3520... Val Loss: 2.0937\n",
      "Epoch: 1/25... Step: 1870... Loss: 1.1770... Val Loss: 2.0490\n",
      "Epoch: 1/25... Step: 1880... Loss: 1.4379... Val Loss: 2.0639\n",
      "Epoch: 1/25... Step: 1890... Loss: 1.4507... Val Loss: 2.0738\n",
      "Epoch: 1/25... Step: 1900... Loss: 1.6135... Val Loss: 2.0825\n",
      "Epoch: 1/25... Step: 1910... Loss: 0.9347... Val Loss: 2.1373\n",
      "Epoch: 1/25... Step: 1920... Loss: 1.4146... Val Loss: 2.2866\n",
      "Epoch: 1/25... Step: 1930... Loss: 1.2820... Val Loss: 2.2258\n",
      "Epoch: 1/25... Step: 1940... Loss: 1.3738... Val Loss: 2.1468\n",
      "Epoch: 1/25... Step: 1950... Loss: 1.5760... Val Loss: 2.2231\n",
      "Epoch: 1/25... Step: 1960... Loss: 1.2021... Val Loss: 2.1684\n",
      "Epoch: 1/25... Step: 1970... Loss: 1.7152... Val Loss: 2.1523\n",
      "Epoch: 1/25... Step: 1980... Loss: 1.3947... Val Loss: 2.1366\n",
      "Epoch: 1/25... Step: 1990... Loss: 1.6225... Val Loss: 2.1035\n",
      "Epoch: 1/25... Step: 2000... Loss: 1.1419... Val Loss: 2.1253\n",
      "Epoch: 1/25... Step: 2010... Loss: 1.9039... Val Loss: 2.2666\n",
      "Epoch: 1/25... Step: 2020... Loss: 1.3947... Val Loss: 2.2081\n",
      "Epoch: 1/25... Step: 2030... Loss: 0.9898... Val Loss: 2.1329\n",
      "Epoch: 1/25... Step: 2040... Loss: 1.3646... Val Loss: 2.1725\n",
      "Epoch: 1/25... Step: 2050... Loss: 1.1271... Val Loss: 2.1608\n",
      "Epoch: 1/25... Step: 2060... Loss: 1.5565... Val Loss: 2.1536\n",
      "Epoch: 1/25... Step: 2070... Loss: 1.3127... Val Loss: 2.2165\n",
      "Epoch: 1/25... Step: 2080... Loss: 1.3811... Val Loss: 2.1564\n",
      "Epoch: 1/25... Step: 2090... Loss: 1.9068... Val Loss: 2.1347\n",
      "Epoch: 1/25... Step: 2100... Loss: 1.7433... Val Loss: 2.1148\n",
      "Epoch: 1/25... Step: 2110... Loss: 1.7701... Val Loss: 2.1103\n",
      "Epoch: 1/25... Step: 2120... Loss: 0.7131... Val Loss: 2.1009\n",
      "Epoch: 1/25... Step: 2130... Loss: 0.7158... Val Loss: 2.1323\n",
      "Epoch: 1/25... Step: 2140... Loss: 0.6782... Val Loss: 2.1756\n",
      "Epoch: 1/25... Step: 2150... Loss: 0.3595... Val Loss: 2.1510\n",
      "Epoch: 1/25... Step: 2160... Loss: 0.7701... Val Loss: 2.1665\n",
      "Epoch: 1/25... Step: 2170... Loss: 1.4772... Val Loss: 2.0672\n",
      "Epoch: 1/25... Step: 2180... Loss: 1.0611... Val Loss: 2.0365\n",
      "Epoch: 1/25... Step: 2190... Loss: 1.0845... Val Loss: 2.0856\n",
      "Epoch: 1/25... Step: 2200... Loss: 2.0352... Val Loss: 2.0979\n",
      "Epoch: 1/25... Step: 2210... Loss: 1.0387... Val Loss: 2.0415\n",
      "Epoch: 1/25... Step: 2220... Loss: 0.9600... Val Loss: 2.0582\n",
      "Epoch: 1/25... Step: 2230... Loss: 0.7917... Val Loss: 2.0907\n",
      "Epoch: 1/25... Step: 2240... Loss: 0.4175... Val Loss: 2.1204\n",
      "Epoch: 1/25... Step: 2250... Loss: 1.0632... Val Loss: 2.0753\n",
      "Epoch: 1/25... Step: 2260... Loss: 0.8033... Val Loss: 2.0268\n",
      "Epoch: 1/25... Step: 2270... Loss: 0.8549... Val Loss: 2.0218\n",
      "Epoch: 1/25... Step: 2280... Loss: 0.5962... Val Loss: 2.0686\n",
      "Epoch: 1/25... Step: 2290... Loss: 1.2715... Val Loss: 2.0591\n",
      "Epoch: 1/25... Step: 2300... Loss: 0.9063... Val Loss: 2.0507\n",
      "Epoch: 1/25... Step: 2310... Loss: 1.5414... Val Loss: 2.0416\n",
      "Epoch: 1/25... Step: 2320... Loss: 0.9648... Val Loss: 2.0011\n",
      "Epoch: 1/25... Step: 2330... Loss: 1.1816... Val Loss: 2.0917\n",
      "Epoch: 1/25... Step: 2340... Loss: 0.9178... Val Loss: 2.0401\n",
      "Epoch: 1/25... Step: 2350... Loss: 0.8381... Val Loss: 2.0413\n",
      "Epoch: 1/25... Step: 2360... Loss: 1.7147... Val Loss: 2.0283\n",
      "Epoch: 1/25... Step: 2370... Loss: 0.7856... Val Loss: 2.0558\n",
      "Epoch: 1/25... Step: 2380... Loss: 1.4085... Val Loss: 2.0372\n",
      "Epoch: 1/25... Step: 2390... Loss: 0.3940... Val Loss: 2.0657\n",
      "Epoch: 1/25... Step: 2400... Loss: 1.1850... Val Loss: 2.0758\n",
      "Epoch: 1/25... Step: 2410... Loss: 0.8956... Val Loss: 2.0303\n",
      "Epoch: 1/25... Step: 2420... Loss: 1.5035... Val Loss: 2.0326\n",
      "Epoch: 1/25... Step: 2430... Loss: 1.4921... Val Loss: 2.0812\n",
      "Epoch: 1/25... Step: 2440... Loss: 0.9622... Val Loss: 2.0568\n",
      "Epoch: 1/25... Step: 2450... Loss: 1.6380... Val Loss: 2.0157\n",
      "Epoch: 1/25... Step: 2460... Loss: 0.6937... Val Loss: 2.0460\n",
      "Epoch: 1/25... Step: 2470... Loss: 1.1511... Val Loss: 2.0275\n",
      "Epoch: 1/25... Step: 2480... Loss: 0.6310... Val Loss: 2.0933\n",
      "Epoch: 1/25... Step: 2490... Loss: 0.6259... Val Loss: 2.0743\n",
      "Epoch: 1/25... Step: 2500... Loss: 0.4865... Val Loss: 2.0494\n",
      "Epoch: 1/25... Step: 2510... Loss: 1.3115... Val Loss: 2.0809\n",
      "Epoch: 1/25... Step: 2520... Loss: 2.2647... Val Loss: 1.9841\n",
      "Epoch: 1/25... Step: 2530... Loss: 1.7901... Val Loss: 1.9763\n",
      "Epoch: 1/25... Step: 2540... Loss: 0.9679... Val Loss: 1.9576\n",
      "Epoch: 1/25... Step: 2550... Loss: 1.8913... Val Loss: 1.9950\n",
      "Epoch: 1/25... Step: 2560... Loss: 2.4575... Val Loss: 1.9530\n",
      "Epoch: 1/25... Step: 2570... Loss: 2.3796... Val Loss: 1.9097\n",
      "Epoch: 1/25... Step: 2580... Loss: 1.0227... Val Loss: 1.8891\n",
      "Epoch: 1/25... Step: 2590... Loss: 2.4577... Val Loss: 1.8789\n",
      "Epoch: 1/25... Step: 2600... Loss: 2.0101... Val Loss: 1.8789\n",
      "Epoch: 1/25... Step: 2610... Loss: 1.3580... Val Loss: 1.8682\n",
      "Epoch: 1/25... Step: 2620... Loss: 0.8337... Val Loss: 1.8631\n",
      "Epoch: 1/25... Step: 2630... Loss: 1.2952... Val Loss: 1.8738\n",
      "Epoch: 1/25... Step: 2640... Loss: 2.0345... Val Loss: 1.8736\n",
      "Epoch: 1/25... Step: 2650... Loss: 1.5578... Val Loss: 1.8859\n",
      "Epoch: 1/25... Step: 2660... Loss: 1.8840... Val Loss: 1.9010\n",
      "Epoch: 1/25... Step: 2670... Loss: 2.5629... Val Loss: 1.9176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25... Step: 2680... Loss: 2.2113... Val Loss: 1.9035\n",
      "Epoch: 1/25... Step: 2690... Loss: 2.6922... Val Loss: 1.8731\n",
      "Epoch: 1/25... Step: 2700... Loss: 1.7524... Val Loss: 1.8734\n",
      "Epoch: 1/25... Step: 2710... Loss: 1.0603... Val Loss: 1.8496\n",
      "Epoch: 1/25... Step: 2720... Loss: 0.6981... Val Loss: 1.8546\n",
      "Epoch: 1/25... Step: 2730... Loss: 1.3079... Val Loss: 1.9394\n",
      "Epoch: 1/25... Step: 2740... Loss: 1.6397... Val Loss: 1.8733\n",
      "Epoch: 1/25... Step: 2750... Loss: 1.3436... Val Loss: 1.8694\n",
      "Epoch: 1/25... Step: 2760... Loss: 1.4824... Val Loss: 1.8918\n",
      "Epoch: 1/25... Step: 2770... Loss: 1.3203... Val Loss: 1.9477\n",
      "Epoch: 1/25... Step: 2780... Loss: 1.3626... Val Loss: 1.8886\n",
      "Epoch: 1/25... Step: 2790... Loss: 1.3850... Val Loss: 1.8939\n",
      "Epoch: 1/25... Step: 2800... Loss: 1.7738... Val Loss: 1.9232\n",
      "Epoch: 1/25... Step: 2810... Loss: 1.1604... Val Loss: 1.9366\n",
      "Epoch: 1/25... Step: 2820... Loss: 1.4819... Val Loss: 1.9691\n",
      "Epoch: 1/25... Step: 2830... Loss: 1.2749... Val Loss: 1.9534\n",
      "Epoch: 1/25... Step: 2840... Loss: 1.8740... Val Loss: 1.9262\n",
      "Epoch: 1/25... Step: 2850... Loss: 1.2348... Val Loss: 1.9269\n",
      "Epoch: 1/25... Step: 2860... Loss: 1.3514... Val Loss: 1.8996\n",
      "Epoch: 1/25... Step: 2870... Loss: 1.9934... Val Loss: 1.9224\n",
      "Epoch: 1/25... Step: 2880... Loss: 1.7621... Val Loss: 1.8699\n",
      "Epoch: 1/25... Step: 2890... Loss: 1.1439... Val Loss: 1.8259\n",
      "Epoch: 1/25... Step: 2900... Loss: 1.8416... Val Loss: 1.8331\n",
      "Epoch: 1/25... Step: 2910... Loss: 1.4039... Val Loss: 1.8693\n",
      "Epoch: 1/25... Step: 2920... Loss: 1.1824... Val Loss: 1.9211\n",
      "Epoch: 1/25... Step: 2930... Loss: 1.0854... Val Loss: 1.8953\n",
      "Epoch: 1/25... Step: 2940... Loss: 1.1862... Val Loss: 1.8996\n",
      "Epoch: 1/25... Step: 2950... Loss: 1.2471... Val Loss: 1.8785\n",
      "Epoch: 1/25... Step: 2960... Loss: 1.6360... Val Loss: 1.8653\n",
      "Epoch: 1/25... Step: 2970... Loss: 1.3111... Val Loss: 1.8909\n",
      "Epoch: 1/25... Step: 2980... Loss: 0.8393... Val Loss: 1.8867\n",
      "Epoch: 1/25... Step: 2990... Loss: 1.3401... Val Loss: 1.9057\n",
      "Epoch: 1/25... Step: 3000... Loss: 1.4056... Val Loss: 1.9120\n",
      "Epoch: 1/25... Step: 3010... Loss: 1.2137... Val Loss: 1.9328\n",
      "Epoch: 1/25... Step: 3020... Loss: 0.9404... Val Loss: 1.9183\n",
      "Epoch: 1/25... Step: 3030... Loss: 0.7577... Val Loss: 1.9590\n",
      "Epoch: 1/25... Step: 3040... Loss: 0.8549... Val Loss: 2.0606\n",
      "Epoch: 1/25... Step: 3050... Loss: 1.0256... Val Loss: 2.0406\n",
      "Epoch: 1/25... Step: 3060... Loss: 0.9684... Val Loss: 2.0630\n",
      "Epoch: 1/25... Step: 3070... Loss: 1.3708... Val Loss: 2.0190\n",
      "Epoch: 1/25... Step: 3080... Loss: 0.7576... Val Loss: 1.9371\n",
      "Epoch: 1/25... Step: 3090... Loss: 1.3936... Val Loss: 1.8928\n",
      "Epoch: 1/25... Step: 3100... Loss: 1.3304... Val Loss: 1.8679\n",
      "Epoch: 1/25... Step: 3110... Loss: 0.9660... Val Loss: 1.8895\n",
      "Epoch: 1/25... Step: 3120... Loss: 0.6417... Val Loss: 1.9412\n",
      "Epoch: 1/25... Step: 3130... Loss: 1.3154... Val Loss: 1.9602\n",
      "Epoch: 1/25... Step: 3140... Loss: 1.5045... Val Loss: 1.9036\n",
      "Epoch: 1/25... Step: 3150... Loss: 1.3105... Val Loss: 1.8898\n",
      "Epoch: 1/25... Step: 3160... Loss: 0.9186... Val Loss: 1.8850\n",
      "Epoch: 1/25... Step: 3170... Loss: 1.8791... Val Loss: 1.9312\n",
      "Epoch: 1/25... Step: 3180... Loss: 1.9065... Val Loss: 1.9063\n",
      "Epoch: 1/25... Step: 3190... Loss: 1.1036... Val Loss: 1.8878\n",
      "Epoch: 1/25... Step: 3200... Loss: 0.9450... Val Loss: 1.9041\n",
      "Epoch: 1/25... Step: 3210... Loss: 0.9963... Val Loss: 1.9744\n",
      "Epoch: 1/25... Step: 3220... Loss: 1.6615... Val Loss: 1.9916\n",
      "Epoch: 1/25... Step: 3230... Loss: 1.0163... Val Loss: 1.9774\n",
      "Epoch: 1/25... Step: 3240... Loss: 1.6112... Val Loss: 1.9704\n",
      "Epoch: 1/25... Step: 3250... Loss: 0.8444... Val Loss: 1.9513\n",
      "Epoch: 1/25... Step: 3260... Loss: 1.4703... Val Loss: 2.0288\n",
      "Epoch: 1/25... Step: 3270... Loss: 1.8026... Val Loss: 1.8988\n",
      "Epoch: 1/25... Step: 3280... Loss: 1.3699... Val Loss: 1.8806\n",
      "Epoch: 1/25... Step: 3290... Loss: 1.1060... Val Loss: 1.8965\n",
      "Epoch: 1/25... Step: 3300... Loss: 1.2618... Val Loss: 1.9390\n",
      "Epoch: 1/25... Step: 3310... Loss: 1.2695... Val Loss: 1.9287\n",
      "Epoch: 1/25... Step: 3320... Loss: 1.4564... Val Loss: 1.9781\n",
      "Epoch: 1/25... Step: 3330... Loss: 0.9536... Val Loss: 2.0860\n",
      "Epoch: 1/25... Step: 3340... Loss: 0.3882... Val Loss: 2.1571\n",
      "Epoch: 1/25... Step: 3350... Loss: 2.0439... Val Loss: 2.2330\n",
      "Epoch: 1/25... Step: 3360... Loss: 0.9175... Val Loss: 2.1048\n",
      "Epoch: 1/25... Step: 3370... Loss: 1.8284... Val Loss: 2.0262\n",
      "Epoch: 1/25... Step: 3380... Loss: 1.0099... Val Loss: 2.0420\n",
      "Epoch: 1/25... Step: 3390... Loss: 1.1692... Val Loss: 1.9970\n",
      "Epoch: 1/25... Step: 3400... Loss: 1.1120... Val Loss: 2.0203\n",
      "Epoch: 1/25... Step: 3410... Loss: 0.7294... Val Loss: 2.0901\n",
      "Epoch: 1/25... Step: 3420... Loss: 1.4793... Val Loss: 1.9951\n",
      "Epoch: 1/25... Step: 3430... Loss: 1.6469... Val Loss: 1.9232\n",
      "Epoch: 1/25... Step: 3440... Loss: 1.2268... Val Loss: 1.9068\n",
      "Epoch: 1/25... Step: 3450... Loss: 1.0373... Val Loss: 1.8980\n",
      "Epoch: 1/25... Step: 3460... Loss: 1.8991... Val Loss: 1.9122\n",
      "Epoch: 1/25... Step: 3470... Loss: 1.3371... Val Loss: 1.9409\n",
      "Epoch: 1/25... Step: 3480... Loss: 1.3629... Val Loss: 1.9854\n",
      "Epoch: 1/25... Step: 3490... Loss: 1.1676... Val Loss: 1.9675\n",
      "Epoch: 1/25... Step: 3500... Loss: 1.0531... Val Loss: 1.9679\n",
      "Epoch: 1/25... Step: 3510... Loss: 1.4413... Val Loss: 1.8916\n",
      "Epoch: 1/25... Step: 3520... Loss: 2.3658... Val Loss: 1.8541\n",
      "Epoch: 1/25... Step: 3530... Loss: 1.0245... Val Loss: 1.8729\n",
      "Epoch: 1/25... Step: 3540... Loss: 1.0328... Val Loss: 1.8633\n",
      "Epoch: 1/25... Step: 3550... Loss: 1.7387... Val Loss: 1.8287\n",
      "Epoch: 1/25... Step: 3560... Loss: 1.1317... Val Loss: 1.8217\n",
      "Epoch: 1/25... Step: 3570... Loss: 1.1501... Val Loss: 1.8367\n",
      "Epoch: 1/25... Step: 3580... Loss: 1.6378... Val Loss: 1.8576\n",
      "Epoch: 1/25... Step: 3590... Loss: 1.2293... Val Loss: 1.8181\n",
      "Epoch: 1/25... Step: 3600... Loss: 1.1887... Val Loss: 1.7895\n",
      "Epoch: 1/25... Step: 3610... Loss: 1.8899... Val Loss: 1.8172\n",
      "Epoch: 1/25... Step: 3620... Loss: 1.6696... Val Loss: 1.8321\n",
      "Epoch: 1/25... Step: 3630... Loss: 1.6144... Val Loss: 1.8141\n",
      "Epoch: 1/25... Step: 3640... Loss: 1.1219... Val Loss: 1.8368\n",
      "Epoch: 1/25... Step: 3650... Loss: 0.8279... Val Loss: 1.8145\n",
      "Epoch: 1/25... Step: 3660... Loss: 1.6870... Val Loss: 1.8044\n",
      "Epoch: 1/25... Step: 3670... Loss: 1.3454... Val Loss: 1.7964\n",
      "Epoch: 1/25... Step: 3680... Loss: 0.9392... Val Loss: 1.8261\n",
      "Epoch: 1/25... Step: 3690... Loss: 1.5874... Val Loss: 1.9145\n",
      "Epoch: 1/25... Step: 3700... Loss: 1.1333... Val Loss: 1.8405\n",
      "Epoch: 1/25... Step: 3710... Loss: 2.8490... Val Loss: 1.7431\n",
      "Epoch: 1/25... Step: 3720... Loss: 1.4516... Val Loss: 1.7508\n",
      "Epoch: 1/25... Step: 3730... Loss: 1.8772... Val Loss: 1.7496\n",
      "Epoch: 2/25... Step: 3740... Loss: 1.2820... Val Loss: 1.7430\n",
      "Epoch: 2/25... Step: 3750... Loss: 1.7500... Val Loss: 1.7753\n",
      "Epoch: 2/25... Step: 3760... Loss: 1.1113... Val Loss: 1.8477\n",
      "Epoch: 2/25... Step: 3770... Loss: 0.8206... Val Loss: 1.8576\n",
      "Epoch: 2/25... Step: 3780... Loss: 1.4671... Val Loss: 1.8647\n",
      "Epoch: 2/25... Step: 3790... Loss: 1.4040... Val Loss: 1.9039\n",
      "Epoch: 2/25... Step: 3800... Loss: 2.1212... Val Loss: 1.9200\n",
      "Epoch: 2/25... Step: 3810... Loss: 0.4590... Val Loss: 1.9252\n",
      "Epoch: 2/25... Step: 3820... Loss: 0.9867... Val Loss: 1.9363\n",
      "Epoch: 2/25... Step: 3830... Loss: 0.7160... Val Loss: 1.8787\n",
      "Epoch: 2/25... Step: 3840... Loss: 0.6273... Val Loss: 1.8861\n",
      "Epoch: 2/25... Step: 3850... Loss: 0.7816... Val Loss: 1.9234\n",
      "Epoch: 2/25... Step: 3860... Loss: 0.6859... Val Loss: 1.9132\n",
      "Epoch: 2/25... Step: 3870... Loss: 0.5505... Val Loss: 1.9081\n",
      "Epoch: 2/25... Step: 3880... Loss: 1.1222... Val Loss: 1.9352\n",
      "Epoch: 2/25... Step: 3890... Loss: 0.9081... Val Loss: 1.9030\n",
      "Epoch: 2/25... Step: 3900... Loss: 0.4039... Val Loss: 1.8643\n",
      "Epoch: 2/25... Step: 3910... Loss: 1.0239... Val Loss: 1.9277\n",
      "Epoch: 2/25... Step: 3920... Loss: 0.3387... Val Loss: 1.9477\n",
      "Epoch: 2/25... Step: 3930... Loss: 0.4923... Val Loss: 1.9645\n",
      "Epoch: 2/25... Step: 3940... Loss: 0.8316... Val Loss: 1.9696\n",
      "Epoch: 2/25... Step: 3950... Loss: 0.8388... Val Loss: 1.9369\n",
      "Epoch: 2/25... Step: 3960... Loss: 0.6592... Val Loss: 1.9219\n",
      "Epoch: 2/25... Step: 3970... Loss: 0.4427... Val Loss: 1.8997\n",
      "Epoch: 2/25... Step: 3980... Loss: 1.6238... Val Loss: 1.9320\n",
      "Epoch: 2/25... Step: 3990... Loss: 0.7882... Val Loss: 1.8943\n",
      "Epoch: 2/25... Step: 4000... Loss: 0.5813... Val Loss: 1.9098\n"
     ]
    }
   ],
   "source": [
    "if 'net' in locals():\n",
    "    del net\n",
    "\n",
    "\n",
    "\n",
    "net = CharRNN(chars, n_hidden=795, n_layers=3)\n",
    "\n",
    "n_seqs, n_steps = 128, 100\n",
    "train(net, encoded, epochs=25, n_seqs=200, n_steps=160, lr=0.001, cuda=False, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'tokens': net.chars}\n",
    "with open('rnn.net', 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(net, size, prime='The', top_k=None, cuda=False):\n",
    "        \n",
    "    if cuda:\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = net.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = net.predict(ch, h, cuda=cuda, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = net.predict(chars[-1], h, cuda=cuda, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msid/ltb3/anaconda3/envs/nestorDev/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/msid/ltb3/anaconda3/envs/nestorDev/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/msid/ltb3/anaconda3/envs/nestorDev/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thel on stoem\n",
      "  repair hre line of sensticy\n",
      "  loose cys.dr2 sidarn on lube sha24.\n",
      "  repair leak on atarbo\n",
      "  grease lont handranigel boom\n",
      "  leaking lose stor hyd hose\n",
      "  replace lh braken tooth\n",
      "  replace bucket she tooth\n",
      "  lep. sod lost ref replace tooth\n",
      "  replace bucket teet\n",
      "  chs taint ox bucket tin\n",
      "  stait light on bucket tooth\n",
      "  replace movol lh rh ro-llak hoses.\n",
      "  replace fault rh engineo\n",
      "  replace sliw hoserssion\n",
      "  repair hid ressuil famind tor\n",
      "  host.. poned tavel sed refint replaces\n",
      "  broken grease line on bucket teet\n",
      "  replace lh prh pump change fie lefters\n",
      "  crack ater hip in bucket toothr low\n",
      "  hyd lows\n",
      "  low low hose\n",
      "  replace hydraulic line\n",
      "  boom filt on bucket out\n",
      "  leakinagr leaks on bucket on boom\n",
      "  replace missing bump engine scab tool loss\n",
      "  repair on lh eaging shprouns\n",
      "  replace supper grease ligh shd24\n",
      "  repair hreadar out\n",
      "  rh engine breat hag deming at entine\n",
      "  changeout l fint on chackend\n",
      "  will not radirouts\n",
      "  leatitor rigen swing hydraulic oil\n",
      "  blownny reslace pise broken grease line\n",
      "  repair broken grease line\n",
      "  out replace lh engine oil firter oin oil leak\n",
      "  replace rh1000ro- to slew lube pam\n",
      "  l/h eng oil leak th tooth\n",
      "  replace th tope grease lines\n",
      "  lh engine bucket tooth hose\n",
      "  repair oil leak\n",
      "  outing air sine r/h rumping hose\n",
      "  filt sline pipe\n",
      "  repair lh eng\n",
      "  trackuping to lake\n",
      "  oil leak swing adarting\n",
      "  chonge out leaking fat missing\n",
      "  replace leathang leaking\n",
      "  replace repear hose leak\n",
      "  replace gauged shd24\n",
      "  crownage sh bunking changeout\n",
      "  hyd low broken grease lines\n",
      "  lh prabe low\n",
      "  shd mannore broken top boom both\n",
      "  sydlow switg on bots\n",
      "  lep al broken grease lines on bucket\n",
      "  replace r/h engine shutting.\n",
      "  replace grease lige on bucket\n",
      "  refinat rh pump pump pip\n",
      "  swite bucket cealind lh pump\n",
      "  riseal l/h surp oil fil shd24\n",
      "  fare cyliged leak fault\n",
      "  replace lube sip\n",
      "  r/h tubl dararal\n",
      " \n",
      "  replace bleak on pim pump\n",
      "\n",
      "  replace rh atamone\n",
      "  shd to bucked collworing\n",
      "  gaubd renial boom leak\n",
      "  replace blowne shd204\n",
      "  fit repair oil teak filter boom nos\n",
      "  fint sware switcting hose\n",
      "  replace hydraulic hys shew pump\n",
      "  repair lube pam\n",
      "  honeoner oil leak on atcer fault liged far\n",
      "  grease line on r/h stark cylinder\n",
      "  remain replace leating on bucket\n",
      "  rh side block on gueader sto low or\n",
      "  change out l/h slew motor\n",
      "  lh engine sliwn hos on aider\n",
      "  replace broken grease line on r/h stint\n",
      "  repairs lub oil leak\n",
      "  lh fault fin roplear repair hyd anc oil com rag\n",
      "  rh slew mount lube tint\n",
      "  leak ng tost. minner c/ow rollar\n",
      "  lh pto mover hose bear serve creat\n",
      "  replace blown hyd hose\n",
      "  oil leak on lhs low pump cker\n",
      "  replace grease lipe both shs hd24\n",
      "  hyd leaking fault\n",
      "  leak an pressure filler low\n",
      "  cooltr leats\n",
      "  stam tom pro suptor\n",
      "  r/h teak demp rh broken grease line of broken\n",
      "  changeout ~ lube bunke fant\n",
      "  sh engine wottrif slam\n",
      "  liget ctoolh\n",
      "  leak now rh noo- reaking\n",
      "  change out ~ reft fuel lube flow motor\n",
      "  sh124 slew pump\n",
      "  boom leaks\n",
      "  gheaud ail leak\n",
      "  boom fault sch sed mo not reth\n",
      "  r/h engine oil leak rh sipwing swilh\n",
      "  leaking alat\n",
      "  replace back cabure hose shisc deplingion goute\n",
      "  adcortarerex\n",
      "  werhars ault\n",
      "  replace hyd. tan\n",
      "  oil leak andeler braked tyl.\n",
      "  reseal pump replace adtine.\n",
      "  engine loon blownd\n",
      "  replace missing bucket graage lines lh hose low pleak lh\n",
      "  replace rh eng oil laft hose leaking\n",
      "  switch fro pins\n",
      "  grease lube bucket bo missing\n",
      "  repair required toor broken\n",
      "  lh stark blowngr\n",
      "  loone plew slower car pro line\n",
      "  oil leak fan to plest\n",
      "  repair grease lube slew pressssion\n",
      "  repair oil leaks l/h engine\n",
      "  ont far pipe blown roten fir cleeren lowing handoral\n",
      "  oil leak rh propel moting foum tamp\n",
      "  changeout rh stark cylinder\n",
      "  oil leak l/h boom of lube maurint\n",
      "  rh1 fint rreasirs lotoot blown\n",
      "  replace light fro leaking ste bucket\n",
      "  repair track andany.\n",
      "  broken grease line on bucket boom\n",
      "  clabe mithy hase finter hose\n",
      "  bucket fan replace lh sipe moin\n",
      "  rh pipo swarting lop slowt ho leak\n",
      "  replace leak replace to lube track matiens\n",
      "  replace lube finar suppers\n",
      "  slew hose fan ty pump\n",
      "  oil leak rh file tip canboot blown motor\n",
      "  broken grease line on bucket tank\n",
      "  for bure sliw boxt ster bols l/hes\n",
      "  refity d maunting fyl pints send\n",
      "  blown hydraulic fiel sedle\n",
      "  broken slow hose\n",
      "  replace mins al pump\n",
      "  back engine systam ple\n",
      "  r/h engion filler anar cooming shd24\n",
      "  oil leak at rh broken\n",
      "  replace crack doltex on booss\n",
      "  lube fault leaking trecs on bucket\n",
      "  l/h eng senor trepl arald sine box\n",
      "  exhusst bol furlt\n",
      "  leak r/h not roller hose leaking\n",
      "  wir preaser leaking hald ont\n",
      "  chongeot refial rh engines\n",
      "  replace light see hys fal lanker faul pro\n",
      "  broken grease line on lube lost\n",
      "  lost prese ox repair leak\n",
      "  remoirer grease lines fan bolm\n",
      "  replace hydrailich sl won rh rengion\n",
      "  repair hose hose lak font shd4\n",
      "  bucket grease line on bucket sher\n",
      "  replace to lube pump\n",
      "  blown hydraulic oil leak\n",
      "  rh eng bolt coolant lh bucket\n",
      "  repair bolts leak pin.\n",
      "  replace bucket toel\n",
      "  replace lh engine worring oil leaks te motor\n",
      "  repair rh lube fant pump shoud\n",
      "  ouling loow llak pressurn leaking\n",
      "  bucket tepte prock shate rh fit\n",
      "  blown rh slew bol\n",
      "  repair cooling al changeout\n",
      "  replace hose slew fat mover\n",
      "  replace shart changeout\n",
      "  replace faral link on boom\n",
      "  scv moing hyd hose finter masing\n",
      "  replace hone off crackede\n",
      "  oil leak and replace lh boom hafdericaline leaking\n",
      "  chengeaut repair rear ox hose\n",
      "  leaking slew cooling\n",
      "  replace reprite tracking bucket\n",
      "  lo strip cap shroud\n",
      "  lh engine cemprose bucket r/h engine\n",
      "  repair h link on bucket\n",
      "  replace hyd adar\n",
      "  replace fat bucket leaking hose on bext\n",
      "  light ald faler lh\n",
      "  replace labe fault lhats full fan pump geade oil shd filler ol hose\n",
      "  refatring of oil broken\n",
      "  blown main fit shisting ups\n",
      "  stow fault\n",
      "  lh eng on stim bultes of\n",
      "  repair lh stick ful buming swith\n",
      "  shd24 heaking on pre sure system camping\n",
      "  repacr low anart stack leak\n",
      "  bolto houls\n",
      "  l/h leak on bucket\n",
      "  oil leak af terco leaking slew\n",
      "  replace moin pressure oil leakin sin\n",
      "  replace loose on pump fint mifine rhyd tamp\n",
      "  labe far p pipsing\n",
      "  oil leak oil\n",
      "  oil leak on replacestaras leaking\n",
      "  lh engine war pint\n",
      "  replace h hrengine bucket fin suppers\n",
      "  repuir lh both engine overelum liaking\n",
      "  r/h engine on bucket th tool\n",
      "  oil leak\n",
      "  broken grease line on bucket\n",
      "  changeout ~ left bucket tooth\n",
      "  repair lh travel botor reltarms\n",
      "  grease leaking boom te pump shd fault\n",
      "  replace line on lh ealing\n",
      "  replace bumstoy gaugil leak nh shd24\n",
      "  oil leak no leak slew leaking\n",
      "  leaking wolting of toot\n",
      "  replace bots shdicging tum\n",
      "  replace lube stick cabarar low\n",
      "  blown of seater camper fout\n",
      "  leaking travel leak at bom\n",
      "  leak fan broken grease line out\n",
      "  hyd leak on bucket tooth\n",
      "  replace missing out shater milning\n",
      "  broken colling lose\n",
      "  replace crack on l/h travel\n",
      "  replace hosed tar hosting contar\n",
      "  suppe rh beom com pump.\n",
      "  fiel afarouter tent ratarmore lowk\n",
      "  rh rh1200-- replace bucket cramp fit oin boone ox cubt plamine broken\n",
      "  replace lube cumpsirg tingting oil leak shs\n",
      "  engine sent mise pump\n",
      "  syp ses ox chabled\n",
      "  slow burnes out leaking\n",
      "  replace blown ste shige.\n",
      "  leak of bucket shd four\n",
      "  oil leak ase leak\n",
      "  broken grease line on bucket\n",
      "  changeout ~ right line shd024\n",
      "  repair oxt\n",
      "  replace blown hose seel cearb\n",
      "  changeout leaking alc bucket.\n",
      "  replace leat on pump leaking\n",
      "  bloon swith shd24 sesline\n",
      "  of  fit s rep in leak alatting\n",
      "  warn re rowering leaks\n",
      "  replace stiw cracks slip shd24\n",
      "  changeout ~ refaler slew motor bow\n",
      "\n",
      "  replace bucket tiot gh hose slew.\n",
      "  ch boom ne sidw leaking blown\n",
      "  car mans seve hydraulic hose\n",
      "  change out riplace hydraulic line\n",
      "  contripair on bucket she dent fiple gearing\n",
      "  repair huse sh turbox\n",
      "  restart hyding toon\n",
      "  lh bto shd20\n",
      "  oil leak an lh slew backs\n",
      "  lh sliw bo swet menor\n",
      "  changeout lh slow boom cylinder\n",
      "  replace shd24 hose on boom\n",
      "  lip.\n",
      "  lh pump sextout rh..\n",
      "  slew motor warr tox\n",
      "  eplace shd24\n",
      "  replace shd cracked hot bucket\n",
      "  replace bucket hoter.\n",
      "  replace fine clam geade on rh tooth\n",
      "  replace bucket tooth\n",
      "  replace lh eng oil gaugt seroo slick\n",
      "  r/h engine pump shd24 rh prate system on bleak\n",
      "  repair cabrater crampung\n",
      "  repair bucket oil cant fif\n",
      "  lob fault cabricyl\n",
      "  replace slew track ing bolt\n",
      "  eaging sew slew rh stem\n",
      "  replace righ ot reaking\n",
      "  replace block hyd hose\n",
      "  rh engen fror grease filter foutt\n",
      "  hasio line l/h side trevol\n",
      "  replace l/h labo rh2 replace l/h comp pemais at fuep burne.\n",
      "  ch pins wor to tort misser\n",
      "  replace h shd24 boom tooth\n",
      "  swattor lh engine\n",
      "  trepead borminging\n",
      "  oil leak on leak\n",
      "  changeout ~ reght preesure butket hyd\n",
      "  boom clam freal shd24\n",
      "  replace bucket clat ins\n",
      "  rh engine warain pressure\n",
      "  repaire guen oil rear adracys\n",
      "  replace leaking\n",
      "  replace stow pip rh tooth ar sld24\n",
      "  oftine sth pump seal on backe\n",
      "  engine oil bol missing hoses\n",
      "  of repairat replace boom at entin hersers\n",
      "  oir alat has iol cex\n",
      "  rh1 engine rolvart missing\n",
      "  sydrum shd24 grease system startor\n",
      "  repair repair to bucket\n",
      "  fit repair grease pump oxes\n",
      "  exhaust filer l/h block\n",
      "  replace boomang fitting on\n",
      "  boom slew l/h eng oil\n",
      "  shd24 scop broken crowders\n",
      "  repair hyd auder teakh\n",
      "  replace startingines an ack macking\n",
      "  remain hydraulic oil lage leaking\n",
      "  r/h bucket treth\n",
      "  r/h eng out relation bolt on\n",
      "  refials realareater\n",
      "  l/h engine oul low roser lop sealing\n",
      "  fal leaking t/\n",
      "  changeout ~ right lunk pump\n",
      "  replace geast sh engine leaking soose bloxss\n",
      "  crease tom faller pro ell\n",
      " \n",
      "  replace broken grease line over shi2\n",
      "\n",
      "  replace r/h engine out\n",
      "  replace r/h plowed hose\n",
      "  r/h engine wront start left rok swetch\n",
      "  repair shd24 ressice prosel\n",
      "  change out n/h trave pump on stack resing\n",
      "  repair oil leak on bucket\n",
      "  replace stect hoses\n",
      "  stefting oil toon oil canditer oil lh\n",
      "  lhs clarb fartary ransicy seal motes\n",
      "  replace lube fault pris on bucket\n",
      "  repair oil leak\n",
      "  r/h engine broken stick hydraulic hose\n",
      "  reseal leaks\n",
      "  broken gheane line on bucket\n",
      "  shd24 refir lube\n",
      "  changeout ~  reftar pamige\n",
      "  lube tank bucket hydraulic oil leaks on cooler\n",
      "  elewers lube system\n",
      "  repair repair slew rexhaust shs24\n",
      "  lube fault\n",
      "  bucket to lh bucket butke.\n",
      "  replace r/h slew bucket\n",
      "  replace rubo tam pupp\n",
      "  replace lube system hount\n",
      "  repair hyd lower anoteo on shd24\n",
      "  repair hyd oil leaks\n",
      "  rh engine oil contrilve pump cyd rad are\n",
      "  changeout blown strove\n",
      "  bucket tooth on scarve luse.\n",
      "  repair lh ergine bucket pump\n",
      "  shd24 machine sever lifit\n",
      "  rh engine wing wunting leak no task\n",
      "  cabel filt repair belw terbot\n",
      "  repair lube pump gard\n",
      "  firter hasging funt sydram inter shre\n",
      "  rh engine switc misting filter shauge\n",
      "  crack damaned syd2 to buck.\n",
      "  grease lube lont motor\n",
      "  change out leaking on boom\n",
      "  replace stick pipe shandeand tep\n",
      "  leaking hose bucket pom fuol no12 changeal blown on ressur/s.\n",
      "  enging ow tark pum\n",
      "  repair lhs require reting h/s remain\n",
      "  repair covtamgs on hyd fillern\n",
      "  rh broken loot minn bockion bot mis\n",
      "  lh air fal roil leaking seep of broken of frant on blown movel on.\n",
      "  bucket frooth lh filter oil lu/s leaking\n",
      "  changeaut lh engine stick to pump\n",
      "  replace lh file filting line\n",
      "  replace con rubur hydraulics\n",
      "  hos on bucket tump fil clowes\n",
      "  lh engine lwant on r/h slew motor\n",
      "  low on boom hose on bucket\n",
      "  loose stipsty stick. boom\n",
      "  changeout replace far ce trakes\n",
      "  replace acamider frocting shd2\n",
      "  off coaltrak adiplers\n",
      "  oil leak\n",
      "  leaking ar ator tooth\n",
      "  replace blown rh slew leaks\n",
      "  changeant haning oil leak stick\n",
      "  rh eng ail engite tupp hase on bucket\n",
      "  replace lh plosed\n",
      "  crank low bute pine\n",
      "  slew pipe leaking tem tox shd24\n",
      "  oil leak tan\n",
      "  bocke traken comproter\n",
      "  shite l/h sheed can raterol lank\n",
      "  rh shd024 replace hase fant\n",
      "  cooltrall sene mount..\n",
      "  r/h engine anitit pre aratir hoses\n",
      "  stick pump for rh engine far star\n",
      "  fir lown oil leak\n",
      "  on filters routing low lhas ool pees\n",
      "  repair change lube pump on\n",
      "  l/h track igled fat shd24\n",
      "  leak black lobe mausing\n",
      "  broken grease line shauting\n",
      "  replace l/h track cylinder\n",
      "  encineitalting line sealenstings\n",
      "  lift renain lins wor rich\n",
      "  repair oil leak on bucket bolth\n",
      "  low travel pine\n",
      "  replace low hass on lube fault\n",
      "  jump start sco sund boom leaking\n",
      "  repairs\n",
      "  grease line on bucket\n",
      "  changeout ~ r/h eng f rom not rumine\n",
      "  grease to turbl prisser\n",
      "  repairs l/t fiol bot\n",
      "  engine senor fuel lh engine\n",
      "  blown grease packing\n",
      "  replace leaking bext shut\n",
      "  oil l/h lube ayl leakson rh\n",
      "  replace cool relan repair grease line\n",
      "  l/h engine of bo hyd haseoro\n",
      "  acrideat plo slew pipe\n",
      "  oil leak lh reak ayd leak\n",
      "  r/h side gaug one to hund tark\n",
      "  clam noter coolant moss blom finting lh r/h. boom\n",
      "  rh broken bucket too hose serseo\n",
      "  rh stawt hyd hose\n",
      "  blown grease black to beex lube cylimpte shaut\n",
      "  changeout rh filters\n",
      "  repair to pump cramps\n",
      "  reprace slow cylinder\n",
      "  replace bcom fint rno seder tank\n",
      "  low pleaser since seal falter shd24\n",
      "  roplace replace main rng out\n",
      "  crank ont rol rip repairs\n",
      "  replace replace fout\n",
      "  replace lh super to tooth\n",
      "  rosen oil leak on hose low rh eng\n",
      "  require figat replace leaking r/h engine\n",
      "  replace leaking pin\n",
      "  reckain out syd. tip\n",
      "  changeout ~ lifh fan drame shd24\n",
      "  shd24 front oil leak\n",
      "  hd00024 changeout\n",
      "  reseal pile broken grease line to teps bol\n",
      "  fir plessus\n",
      "  sip ox ste pump oil leak\n",
      "  r/h sow leak sher falting\n",
      "  replace hyd line\n",
      "  repair hose. leaking leaking.\n",
      "  replace hasd on mutor bucket\n",
      "  reseal lh engine sysersion\n",
      "\n",
      "  blown hydraulic hose\n",
      "  boom plo wraming shor\n",
      "  rh engine won't faut\n",
      "  jump start bch engeaged lin hund stick\n",
      "  rh engine leak on boom clamp on boom\n",
      "  repair grease bar cy\n",
      "  hdraulad startor\n",
      "  oil costrat liak toot.\n",
      "  replace slows motor pto mount oil tens o fant fan preseur leftor\n",
      "  engine wyl travel hose\n",
      "  scre lh engine on boom\n",
      "  fut p ropine oil leak far topt\n",
      "  replace hydraulic labe fault\n",
      "  cyl. of tortol brake\n",
      "  r/h engine woon start\n",
      "  r/h eng cant cal fault\n",
      "  lh slew motor rugitor\n",
      "  replace funt on boom\n",
      "  replace ting ades on bucket on soolem\n",
      "  blown grease line oil leak hy ladino\n",
      "  replace hyd hose on bucket\n",
      "  glease l/h pump carin out\n",
      "  replace cabriscal toolh\n",
      "  replace mount bucket tooth\n",
      "  lh engine wolt start\n",
      "  r/h fine pramentors\n",
      "  lube slew motor\n",
      "  replace broken on bucket tighs\n",
      "  repair oil leak hosed servo michines\n",
      "  chickend oil leak starking weer chanderout\n",
      "  replace replace masing out\n",
      "  hand hose lh slew mucning out.\n",
      "  l/h broken grease lines\n",
      "  oil leak fan filel replace rh boom\n",
      "  ontick on light onarbo macnine motor\n",
      "  oil leak rh pump oil leaking\n",
      "  werrot shd24\n",
      "  replace boom\n",
      "  repair contro on bucket\n",
      "  replace contril loter toom\n",
      "  replace reading out boltip\n",
      "  repair stark an tracel leaking\n",
      "  main bucket tooth\n",
      "  replace lh pump coolert\n",
      "  r/h cont seel buto fat missing\n",
      "  rh engine over hase leaking frel shd24\n",
      "  switch l/h seel fillt motor shsers\n",
      "  clamm otor oil leak\n",
      "  fir syd2 leaking h slew miss\n",
      "  replace l/h track line colts\n",
      "  replace slow por\n",
      "  lh floom pouter low plo slew\n",
      "  replace m/h erceers fracting on hose\n",
      "  replace leaking blown leaking on booms\n",
      "  on low on plo pump p pro bulse fault\n",
      "  oil leak\n",
      "  clack seal centrich\n",
      "  replace l/h teak\n",
      "  replace repair relaar fault\n",
      "  repair slew front camp\n",
      "  replace broken lower hyd hose\n",
      "  lube filt r/h sise wear shr boom\n",
      "  enginee oil leak stamp\n",
      "  repair broken bucket on tive shd24\n",
      "  replace leaking switch oul\n",
      "  replace pine rh bucket rop pressid\n",
      "  oil leak at engine\n",
      "  repair r/h ergine\n",
      "  replace texters\n",
      "  cunpin tropeal alarem\n",
      "  changeout ~ rh102-- front lir bugnety.\n",
      "  rh eng buct to rubot reslar blown leaking\n",
      "  leaking hreasing to shd stion\n",
      "  lh engine oil clamp hose\n",
      "  bucket lube al minsing\n",
      "  repair toop hyd rost.\n",
      "  repair shd24 hose blown\n",
      "  clang oil leak\n",
      "  changeout r/h noom shd24\n",
      "  replace filt slife screcys l/h boom\n",
      "  bol slew prass re exhissing\n",
      "  lube leaking hase sentom\n",
      "  changeout ~ brh slew motor contom\n",
      "  rh bucket cylind lines on boom\n",
      "  leak rh slew hydraulic hyd\n",
      "  replace slew l/h seve change\n",
      "  repair slew motor shd24\n",
      "  reseal filter tooth\n",
      "  cever husd slew pump repair broken.\n",
      "  repair broken bolt shrels\n",
      "  changeout ~ right fan backital\n",
      "  engine warn shd24\n",
      "  replace l/h treper tor fal sters\n",
      "  blown on hyd tent- replace tom ghing\n",
      "  werne r/h brake on loos\n",
      "  rplace tint of reaking tan\n",
      "  changeout  lh  uppare air slew\n",
      "  repair leak\n",
      "  l/h slew motor\n",
      "  lipeat lh finte sent on cool.\n",
      "  repair furl sever leaking\n",
      "  rh engine start changerout\n",
      "  changeout ~ laff front on bucket\n",
      "  replace shd faund te tuath\n",
      "  changeout ~ light leak on m/h ending\n",
      "  lh trave contor leaks\n",
      "  r/h slew boolt fittrs looter shd24\n",
      "  rowing hase sents\n",
      "  replace broken bucket line bucket.\n",
      "  repair boom lys\n",
      "  scepe laning oil faul lines\n",
      "  broken grease pintor on shd24\n",
      "  lube leak\n",
      "  replace lip control valve les\n",
      "  replace hyd hose noot oil leak\n",
      "  on shd24 fin risear lowe.\n",
      "  slew hose leaking swer on bucket\n",
      "  cantrico leak\n",
      "  lube sweel filt filter\n",
      "  replace to fault hyd ail compels\n",
      "  change fut boy hreslace ond reator motor\n",
      "  lhs toppumig sedee systom\n",
      "  l/h eng bow p crarss relain on plew th fin slew bured ailty\n",
      "  leaking leaking out\n",
      "  booth supp mover broken geestor shd24 stauley swater chts engine\n",
      "  lube slawe barn on slew mount on boom\n",
      "  crains on broken gnease matip cylinger\n",
      "  oil leak hoses repealer hand bolt\n",
      "  fite prease l/h and on replace bucket tooth\n",
      "  replace broken grease lines.\n",
      "  replace changeout lin hose leak\n",
      "  crack on slew borms\n",
      "  spile serss ridcarerous\n",
      "  changeout ~ reft slaw lof'\n",
      "  slew matore atont\n",
      "  engine shast filt mountils\n",
      "  burkt track hosed.\n",
      "  replace hose leaks sen lh 24\n",
      "  replace grease fault\n",
      "  machine lube funt mrove\n",
      "  repair changeout ~ broken grease line on hose meth stert ramiter low\n",
      "  relair hose stact motor crackeor.\n",
      "  changeout ~ rh120ctroker grease line\n",
      "  replace r/h tump hoses to ter oxhr.\n",
      "  pump sest pipp on bucket hyd hose\n",
      "  fuel leak lh refion cubp on stap lig tram ont oil blown hose\n",
      "  repair lh pump stor pump shosed\n",
      "  changeout lube pamp bucket cooming\n",
      "  rh eng four plin sirv low rextarias shd24\n",
      "  loose oil leak on bucket tooth.\n",
      "  repair grease line on bucket\n",
      "  repair hyd hose belt\n",
      "  repuir rh engine swarn atirg\n",
      "  bcoelen housd shate bracket changeout\n",
      "  gleake stain hydraulic plo lhs on pump leaking\n",
      "  replace broken grease line on bucket tooth\n",
      "  changeout s/p mount comerntor\n",
      "  replace grease pimp stipt\n",
      "  repair boxh seer scep repraces\n",
      "  lube line te broken hose\n",
      "  r/h star foult\n",
      "  broken ghease line oil filting\n",
      "  cealtedr oult candiseat pin\n",
      "  repair l/h bucket lh rh pump compate\n",
      "  lh eng bucket tooth\n",
      "  rh comen gout nout controt\n",
      "  repair hose low lh bucket on replect\n",
      "  replace r/h track cylander\n",
      "  blown grease line on slew filter\n",
      "  slew tex aur broken grease leak on clamp\n",
      "  repair teak\n",
      "  cramp boon motor sepsins\n",
      "  slew back coling on starters\n",
      "  replace lh stick cyl broken of blown hyd leak\n",
      "  rh engine woth stark mauninot\n",
      "  replace bucket tip\n",
      "  hose slew mitan al filters\n",
      "  replace l/h slack to tump roplate fan moff\n",
      "  broken grease line ad rech one of\n",
      "  changeout ~ left filar faull.\n",
      "  blown loose on lh tubk shd24\n",
      "  repoir rrh slew motor\n",
      "  repairs replace his in leak on boom\n",
      "  crack on brake cubbony leaking tootar on bucket\n",
      "  changeout ~ rrh fan remurs on blown\n",
      "  replace bucket oil seal leaking\n",
      "  lep lh blown on boom\n",
      "  light crower pump radiat\n",
      "  hyd tooth\n",
      "  replace back tam cooler tox huss\n",
      "  engine to bhy leak.\n",
      "  replace blown moss\n",
      "  strate fan rublecton box\n",
      "  change out ~ refttart fiolers\n",
      "  crack pain ox subl broken lh stick\n",
      "  replace birnet oil leak lh broken\n",
      "  working aling ser bucket\n",
      "  replace lost on bucket tooth\n",
      "  rh engine worting ont\n",
      "  blown bucket comp swilch fatreas\n",
      "  changeout\n",
      "  rh slew gearbr control rolve\n",
      "  hyd leak an boom on tooth\n",
      "  replace blown oil leak\n",
      "  changeeout rh plo slew mator\n",
      "  changeout ~ light atormald fail fall lube\n",
      "  replace l/h sire hyd oil not or\n",
      "  r/h engine\n",
      "  cterpung lube tamk al bol\n",
      "  replace lube loos wolthanting lint\n",
      "  lube pump filting low shing see fite\n",
      "  omarchinge sev oiler bump leaking\n",
      "  changeout ~ light swirch poipt\n",
      "  repairs reser freeding\n",
      "  rh engine on broken bucket\n",
      "  replace lth out cooler leak\n",
      "  hydraulic leak\n",
      "  overhafe lube pump\n",
      "  re\n"
     ]
    }
   ],
   "source": [
    "print(sample(net, 20000, prime='the', top_k=10, cuda=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rnn.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "    \n",
    "loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "loaded.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample(loaded, 2000, cuda=False, top_k=5, prime=\"replace\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
